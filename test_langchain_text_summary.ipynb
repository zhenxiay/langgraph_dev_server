{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "con = duckdb.connect(database='output.duckdb', read_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌───────────┬───────────┬─────────────────────┬─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬───────────┐\n",
       "│    ID     │  Subject  │ Account External ID │                                                                  Notes                                                                  │                                                         Translation                                                         │ Sentiment │\n",
       "│  varchar  │  varchar  │       varchar       │                                                                 varchar                                                                 │                                                           varchar                                                           │  varchar  │\n",
       "├───────────┼───────────┼─────────────────────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────┤\n",
       "│ 1.731.563 │ STU Visit │ 17.001.696          │ Followed for Primary orders & Balance Payments                                                                                          │ Followed for Primary orders & Balance Payments                                                                              │ Neutral   │\n",
       "│ 1.810.813 │ STU Visit │ 17.001.696          │ Followed for Payments                                                                                                                   │ Followed for Payments                                                                                                       │ Neutral   │\n",
       "│ 1.896.416 │ STU Visit │ 17.001.696          │ Followed for Payment towards Outstanding amount                                                                                         │ Followed for Payment towards Outstanding amount                                                                             │ Neutral   │\n",
       "│ 1.719.403 │ STU Visit │ 17.001.989          │ PO DISCUSSION \\r\\n\\r\\nLIMITED TENDER DISCUSSION \\r\\n\\r\\nO/S FOLLOW UP                                                                   │ PO DISCUSSION\\n\\nLIMITED TENDER DISCUSSION\\n\\nO/S FOLLOW UP                                                                 │ Neutral   │\n",
       "│ 1.656.842 │ STU Visit │ 17.001.989          │ PO DISCUSSION AND O/S FOLLOW UP                                                                                                         │ PO DISCUSSION AND O/S FOLLOW UP                                                                                             │ Neutral   │\n",
       "│ 1.667.890 │ STU Visit │ 17.001.989          │ PO DISCUSSION AND O/S FOLLOW UP\\r\\n\\r\\nO/S - 16805068/-\\r\\n\\r\\nO/D - 10627592/-\\r\\n\\r\\ncommitment given till Feb 10.2.25 for 10627592/- │ PO DISCUSSION AND O/S FOLLOW UP\\n\\nO/S - 16805068/-\\n\\nO/D - 10627592/-\\n\\ncommitment given till Feb 10.2.25 for 10627592/- │ Neutral   │\n",
       "│ 1.671.980 │ STU Visit │ 17.001.989          │ PO DISCUSSION AND O/S FOLLOW UP                                                                                                         │ PO DISCUSSION AND O/S FOLLOW UP                                                                                             │ Neutral   │\n",
       "│ 1.673.938 │ STU Visit │ 17.001.989          │ PO DISCUSSION AND O/S FOLLOW UP                                                                                                         │ PO DISCUSSION AND O/S FOLLOW UP                                                                                             │ Neutral   │\n",
       "│ 1.675.860 │ STU Visit │ 17.001.989          │ PO DISCUSSION AND O/S FOLLOW UP                                                                                                         │ PO DISCUSSION AND O/S FOLLOW UP                                                                                             │ Neutral   │\n",
       "│ 1.714.539 │ STU Visit │ 17.001.989          │ O/S FOLLOW UP - 45 LAC \\r\\n\\r\\nPO DISCUSSION \\r\\n\\r\\n2024 TENDER CLOSED \\r\\n\\r\\nNEW TENDER RELEASE DISCUSSION                           │ O/S FOLLOW UP - 45 LAC\\n\\nPO DISCUSSION\\n\\n2024 TENDER CLOSED\\n\\nNEW TENDER RELEASE DISCUSSION                              │ Neutral   │\n",
       "├───────────┴───────────┴─────────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴───────────┤\n",
       "│ 10 rows                                                                                                                                                                                                                                                                                                               6 columns │\n",
       "└─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.sql(\"SELECT * FROM result_sentiment_analysis LIMIT 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e112b874-bd83-4b1f-bb74-b477ee1c63de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b14ea529-6848-429c-9d65-17e8fbb2ef7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from langchain_openai import AzureChatOpenAI, OpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_classic.chains import LLMChain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from typing import Optional, List\n",
    "import logging\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Disable httpx INFO logs\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "# Also disable openai client logs if needed\n",
    "logging.getLogger(\"openai\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e0d97fc-ade1-4be7-b65c-fcb6c600b3f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50c596c1-cb83-4043-87c1-7c1fd90bc6ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Read input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82773ebf-f6e5-4c3b-8233-b8dbe0fc6f0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_excel_file(\n",
    "        file_path: str,\n",
    "        nrows: int = 128\n",
    "        ) -> pd.DataFrame:\n",
    "    \"\"\"Reads an Excel file and returns a DataFrame.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_excel(file_path, nrows=nrows)\n",
    "        logger.info(f\"Successfully read the Excel file: {file_path}\")\n",
    "        logger.info(f\"Rows loaded: {len(df)}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error reading the Excel file: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89e13fb6-c460-4946-be15-0ffb4c2ed794",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Define class and function to execute the summary & translation task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d11f96f1-f33c-454b-88ef-e93e21d17385",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class NotesSummarizer:\n",
    "    \"\"\"\n",
    "    Summarizes notes from Excel files using OpenAI and LangChain.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model: str = \"gpt-4.1\",\n",
    "        api_version: str =\"2025-01-01-preview\",\n",
    "        azure_endpoint: str = \"https://your-azure-openai-endpoint.openai.azure.com/\",\n",
    "        input_file_path: str = 'text_collection_workshops.xlsx',\n",
    "        nrows: int = 128,\n",
    "        temperature: float = 0,\n",
    "        base_url: Optional[str] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the summarizer with OpenAI credentials.\n",
    "        \n",
    "        Args:\n",
    "            api_key: OpenAI API key\n",
    "            model: Model name (e.g., \"gpt-4o-mini\", \"gpt-4\", \"gpt-3.5-turbo\")\n",
    "            api_version: API version for Azure OpenAI\n",
    "            input_file_path: Path to the input Excel file\n",
    "            nrows: Number of rows to read from the Excel file (Default: 128)\n",
    "            temperature: Temperature for text generation (lower = more focused)\n",
    "            base_url: Optional base URL for OpenAI API (useful for proxies)\n",
    "        \"\"\"\n",
    "        self.llm = AzureChatOpenAI(\n",
    "            azure_deployment=model,\n",
    "            api_version=api_version,\n",
    "            azure_endpoint=azure_endpoint,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        \n",
    "        self.input_file_path = input_file_path\n",
    "        self.nrows = nrows\n",
    "\n",
    "        # Define the summarization prompt\n",
    "        self.prompt_template = PromptTemplate(\n",
    "            input_variables=[\"text\"],\n",
    "            template=\"\"\"Summarize the following text. \n",
    "Keep the summary concise and under 15 words.\n",
    "DO NOT include any personal data in the summary (e.g., names, email, locations).\n",
    "The summary should be written in English, regardless of input language.\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "Summary:\"\"\"\n",
    "        )\n",
    "\n",
    "        # Define the translation prompt\n",
    "        self.prompt_template_translation = PromptTemplate(\n",
    "            input_variables=[\"text\"],\n",
    "            template=\"\"\"Identify the language of the following text.\n",
    "If it is not English, then translate the following text into English language.\n",
    "Keep the length of the translation under 20 words.\n",
    "DO NOT include any personal data in the summary (e.g., names, email, locations).\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "Summary:\"\"\"\n",
    "        )\n",
    "        \n",
    "        # Create the summarization chain\n",
    "        #self.summarization_chain = LLMChain(\n",
    "        #    llm=self.llm,\n",
    "        #    prompt=self.prompt_template\n",
    "        #)\n",
    "        \n",
    "        #logger.info(f\"Excel Notes Summarizer initialized with model: {model}\")\n",
    "\n",
    "        # Create the summarization chain\n",
    "        #self.translation_chain = LLMChain(\n",
    "        #    llm=self.llm,\n",
    "        #    prompt=self.prompt_template_tanslation\n",
    "        #)\n",
    "        \n",
    "        #logger.info(f\"Excel Notes Translator initialized with model: {model}\")\n",
    "\n",
    "        # Create chains using RunnableSequence (pipe operator)\n",
    "        self.summarization_chain = self.prompt_template | self.llm | StrOutputParser()\n",
    "        logger.info(f\"Excel Notes Summarizer initialized with model: {model}\")\n",
    "\n",
    "        self.translation_chain = self.prompt_template_translation | self.llm | StrOutputParser()\n",
    "        logger.info(f\"Excel Notes Translator initialized with model: {model}\")\n",
    "    \n",
    "    def count_words(self, text: str) -> int:\n",
    "        \"\"\"\n",
    "        Count the number of words in a text string.\n",
    "        \n",
    "        Args:\n",
    "            text: Input text\n",
    "            \n",
    "        Returns:\n",
    "            Number of words\n",
    "        \"\"\"\n",
    "        if pd.isna(text) or not isinstance(text, str):\n",
    "            return 0\n",
    "        return len(str(text).split())\n",
    "    \n",
    "    def summarize_text(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Summarize a single text using the LLM chain.\n",
    "        \n",
    "        Args:\n",
    "            text: Text to summarize\n",
    "            \n",
    "        Returns:\n",
    "            Summarized text\n",
    "        \"\"\"\n",
    "        try:\n",
    "            result = self.summarization_chain.invoke({\"text\": text})\n",
    "            #summary = result[\"text\"].strip()\n",
    "            #return summary\n",
    "            return result.strip()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error summarizing text: {str(e)}\")\n",
    "            return f\"Error: {str(e)}\"\n",
    "        \n",
    "    def translate_text(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Translate a single text using the LLM chain.\n",
    "        \n",
    "        Args:\n",
    "            text: Text to translate\n",
    "            \n",
    "        Returns:\n",
    "            Summarized text\n",
    "        \"\"\"\n",
    "        try:\n",
    "            result = self.summarization_chain.invoke({\"text\": text})\n",
    "            #summary = result[\"text\"].strip()\n",
    "            #return summary\n",
    "            return result.strip()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error translating text: {str(e)}\")\n",
    "            return f\"Error: {str(e)}\"\n",
    "\n",
    "    def process_batch(\n",
    "        self, \n",
    "        batch_df: pd.DataFrame, \n",
    "        notes_column: str, \n",
    "        min_words: int\n",
    "        ) -> List[dict]:\n",
    "        \"\"\"\n",
    "        Process a batch of rows.\n",
    "        \n",
    "        Args:\n",
    "            batch_df: DataFrame batch to process\n",
    "            notes_column: Column name containing notes\n",
    "            min_words: Minimum words for summarization\n",
    "            \n",
    "        Returns:\n",
    "            List of results with summary and tag\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for _, row in batch_df.iterrows():\n",
    "            notes = row[notes_column]\n",
    "            word_count = self.count_words(notes)\n",
    "            \n",
    "            if word_count > min_words:\n",
    "                summary = self.summarize_text(notes)\n",
    "                tag = 'Summarized'\n",
    "            else:\n",
    "                summary = self.translate_text(notes)\n",
    "                tag = 'Translated Only'\n",
    "            \n",
    "            results.append({\n",
    "                'summary': summary,\n",
    "                'tag': tag,\n",
    "                'word_count': word_count\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def process_data(\n",
    "        self,\n",
    "        notes_column: str = \"Notes\",\n",
    "        min_words: int = 25,\n",
    "        batch_size: int = 32\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Process an Excel file and add summarizations.\n",
    "        \n",
    "        Args:\n",
    "            notes_column: Name of the column containing notes\n",
    "            min_words: Minimum number of words required for summarization\n",
    "        \"\"\"\n",
    "        try:\n",
    "            \n",
    "            df = read_excel_file(file_path=self.input_file_path, nrows=self.nrows)\n",
    "\n",
    "            # Check if the Notes column exists\n",
    "            if notes_column not in df.columns:\n",
    "                raise ValueError(f\"Column '{notes_column}' not found in Excel file. Available columns: {df.columns.tolist()}\")\n",
    "            \n",
    "            # Create new columns for summaries\n",
    "            df[\"Summary\"] = \"\"\n",
    "            df[\"Tag\"] = \"\"\n",
    "            \n",
    "            # Create variables for progress tracking\n",
    "            total_rows = len(df)\n",
    "            num_batches = int(np.ceil(total_rows / batch_size))\n",
    "            summarized_count = 0\n",
    "            translated_count = 0\n",
    "\n",
    "            # Process in batches with progress bar\n",
    "            with tqdm(total=num_batches, desc=\"Processing batches\", unit=\"batch\", ncols=100) as pbar_batch:\n",
    "                for batch_idx in range(num_batches):\n",
    "                    start_idx = batch_idx * batch_size\n",
    "                    end_idx = min(start_idx + batch_size, total_rows)\n",
    "                    \n",
    "                    # Get batch\n",
    "                    batch_df = df.iloc[start_idx:end_idx]\n",
    "                    \n",
    "                    # Process batch\n",
    "                    results = self.process_batch(batch_df, notes_column, min_words)\n",
    "                    \n",
    "                    # Update dataframe\n",
    "                    for i, result in enumerate(results):\n",
    "                        row_idx = start_idx + i\n",
    "                        df.at[row_idx, \"Summary\"] = result['summary']\n",
    "                        df.at[row_idx, \"Tag\"] = result['tag']\n",
    "                        \n",
    "                        if result['tag'] == 'Summarized':\n",
    "                            summarized_count += 1\n",
    "                        else:\n",
    "                            translated_count += 1\n",
    "                    \n",
    "                    # Update progress bar\n",
    "                    pbar_batch.update(1)\n",
    "                    pbar_batch.set_postfix({\n",
    "                        'rows': f\"{end_idx}/{total_rows}\",\n",
    "                        'summarized': summarized_count,\n",
    "                        'translated': translated_count\n",
    "                    })\n",
    "            \n",
    "            logger.info(f\"Processing complete!\")\n",
    "            logger.info(f\"Summarized: {summarized_count}, Translated: {translated_count}\")\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing Excel file: {str(e)}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71377df9-adab-4dfb-a3a7-fb17537b099e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Entry Point Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3e022d3-f066-4d9d-b13d-05c6134bf16f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def main(\n",
    "        input_file_path: str,\n",
    "        nrows: int=128\n",
    "        ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Main function to run the Excel summarization process.\n",
    "    \"\"\"\n",
    "       \n",
    "    # Initialize the summarizer\n",
    "    summarizer = NotesSummarizer(\n",
    "        input_file_path=input_file_path,\n",
    "        nrows=nrows,\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    # Process the data\n",
    "    return summarizer.process_data(\n",
    "        notes_column=\"Notes\",\n",
    "        min_words=25\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa2a1d76-1aec-4fa3-98b6-58322357c21e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Execute task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88a008bf-ac21-4cec-a1f5-358af60468eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set NO_PROXY to avoid proxy for localhost connections (important for local MCP server access)\n",
    "os.environ[\"NO_PROXY\"] = \"localhost, 127.0.0.1\"\n",
    "os.environ[\"no_proxy\"] = \"localhost, 127.0.0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f91b95e-fa89-4b18-be8e-93fd1504a5c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_output = main('text_collection.xlsx', nrows=2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63fdb4af-d4a0-4e5a-8b73-67e170f2e1b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Review output data and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7dbb6f12-7933-4e49-87c8-fc62056ef548",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3608a999-2dba-494c-af5b-37c59d2f4588",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_output.to_excel('text_collection_output_with_summaries.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "pandas",
     "langchain",
     "langchain-openai",
     "tqdm",
     "langchain_classic"
    ],
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "test_langchain_text_summary",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
